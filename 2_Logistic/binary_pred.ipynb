{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed30309-5a3c-4746-9d58-40403f992cb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ca9239-ac5a-46ad-a966-2322e32b0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('Dataset/2.02. Binary predictors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206e5f0-82a9-436d-9f67-792796593bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44293ecb-e865-4b31-a2f0-9f52980fe6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data.copy()\n",
    "data['Admitted'] = data['Admitted'].map({'Yes': 1, 'No': 0})\n",
    "data['Gender'] = data['Gender'].map({'Female': 1, 'Male': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10295f43-9b70-4ade-a5ca-ed9a4415f6a0",
   "metadata": {},
   "source": [
    "### **Regression with only 1 predictor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3090e1-a49a-4b5d-95a3-b1a5f030f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Admitted']\n",
    "x1 = data['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4618b4-16c4-47a7-a02a-300b6973abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe05496-59b1-46e6-88a4-a832ff1deb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sm.add_constant(x1)\n",
    "reg_log = sm.Logit(y, x)\n",
    "results_log = reg_log.fit()\n",
    "results_log.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c17e705-a5d3-4b81-818d-99142e26c5b4",
   "metadata": {},
   "source": [
    "How to interpret this table?<br>\n",
    "We can see clearly that, $log(odds_2) = -0.64 + 2.08\\cdot gender_2$, also applies to $gender_1$, therefore<br>\n",
    "<br>\n",
    "$log(\\frac{odds_2}{odds_1}) = 2.08*(gender_2-gender_1)$<br>\n",
    "$log(\\frac{odds_{female}}{odds_{male}} = 2.08(1-0)$<br>\n",
    "$odds_{female} = 7.99 \\cdot odds_{male}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3c55f-ff19-4d53-af7b-1e1b5a75c500",
   "metadata": {},
   "source": [
    "$x^3$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2360ae69-9de0-43a0-836b-f9bf9f33bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Admitted']\n",
    "x1 = data[['SAT', 'Gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68bcd1-1391-498d-9159-31e997e0ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sm.add_constant(x1)\n",
    "reg_log = sm.Logit(y, x)\n",
    "results_log = reg_log.fit()\n",
    "results_log.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d0906b-615d-4893-a0e6-86a2041cdc30",
   "metadata": {},
   "source": [
    "### Checking the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbbecd9-36de-4b28-bb24-24e0f2179418",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9daa59e-7080-43bf-a3b6-41f927d1a33a",
   "metadata": {},
   "source": [
    "This looks awful, lets apply some formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf405aa-729e-4fc7-a59d-ed3b5509a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "results_log.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da49cf-9941-4808-bd17-b50bb2f35325",
   "metadata": {},
   "source": [
    "Comparing with the actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e91c89e-4ef2-4623-9360-e41cb5cf89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(data['Admitted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3700cd-c316-4190-a0dd-b5da2b86f521",
   "metadata": {},
   "source": [
    "We can compare it easily in a table, using a **confusion matrix**\n",
    "\n",
    "\n",
    "```python\n",
    "sm.LogitResults.pred_table()\n",
    "```\n",
    "returns a table which compares the predicted and actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef05706-0482-4b5d-8cc2-1c10dbb01206",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log.pred_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08664db1-ec4f-4a5f-acef-d432160a97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_df = pd.DataFrame(results_log.pred_table())\n",
    "cm_df.columns = {'Predicted 0', 'Predicted 1'}\n",
    "cm_df = cm_df.rename(index= {0: 'Actual 0', 1:'Actual 1'})\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af116c5-384b-498e-8f47-b7056d578d91",
   "metadata": {},
   "source": [
    "Checking the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aaea8e-f278-4e5b-892e-e2d22c74eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.array(cm_df)\n",
    "acc_train = (cm[0, 0] + cm[1, 1])/cm.sum()\n",
    "acc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815823ad-1217-4bb3-88a5-4f1f94887d38",
   "metadata": {},
   "source": [
    "### Testing the model and assess its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff4559-c8f8-4f5d-92d1-86d8fe7c9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv('Dataset/2.03. Test dataset.csv')\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset['Admitted'] = test_dataset['Admitted'].map({'Yes': 1, 'No': 0})\n",
    "test_dataset['Gender'] = test_dataset['Gender'].map({'Female': 1, 'Male': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c0e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62bfc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actual = test_dataset['Admitted']\n",
    "test_data = test_dataset.drop(['Admitted'], axis= 1)\n",
    "test_data  = sm.add_constant(test_data)\n",
    "#test_data = test_data[x.columns.values]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d77138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(data,actual_values,model):\n",
    "        \n",
    "        # Confusion matrix \n",
    "        \n",
    "        # Parameters\n",
    "        # ----------\n",
    "        # data: data frame or array\n",
    "            # data is a data frame formatted in the same way as your input data (without the actual values)\n",
    "            # e.g. const, var1, var2, etc. Order is very important!\n",
    "        # actual_values: data frame or array\n",
    "            # These are the actual values from the test_data\n",
    "            # In the case of a logistic regression, it should be a single column with 0s and 1s\n",
    "            \n",
    "        # model: a LogitResults object\n",
    "            # this is the variable where you have the fitted model \n",
    "            # e.g. results_log in this course\n",
    "        # ----------\n",
    "        \n",
    "        #Predict the values using the Logit model\n",
    "        pred_values = model.predict(data)\n",
    "        # Specify the bins \n",
    "        bins=np.array([0,0.5,1])\n",
    "        # Create a histogram, where if values are between 0 and 0.5 tell will be considered 0\n",
    "        # if they are between 0.5 and 1, they will be considered 1\n",
    "        cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n",
    "        # Calculate the accuracy\n",
    "        accuracy = (cm[0,0]+cm[1,1])/cm.sum()\n",
    "        # Return the confusion matrix and the accuracy\n",
    "        return cm, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3faf0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix with the test data\n",
    "cm = confusion_matrix(test_data,test_actual,results_log)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61969b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format for easier understanding (not needed later on)\n",
    "cm_df = pd.DataFrame(cm[0])\n",
    "cm_df.columns = ['Predicted 0','Predicted 1']\n",
    "cm_df = cm_df.rename(index={0: 'Actual 0',1:'Actual 1'})\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e56ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missclassification rate\n",
    "# Note that Accuracy + Missclassification rate = 1 = 100%\n",
    "print ('Missclassification rate: '+str((1+1)/19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7680e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
